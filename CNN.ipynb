{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YKs7Xm00L5TM",
        "outputId": "d318ad74-d06a-4551-9196-e1589689ffce"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, median_absolute_error\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = \"train_FD004_processed.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "if df.isna().any().any():\n",
        "    print(\"NaN values found in dataset. Removing rows with NaN.\")\n",
        "    df = df.dropna()\n",
        "\n",
        "max_rul = 130 \n",
        "df['RUL'] = df['RUL'].clip(upper=max_rul)\n",
        "\n",
        "WINDOW_SIZE = 30\n",
        "FEATURE_COLS = [col for col in df.columns if col.startswith('op_setting_') or col.startswith('sensor_measurement_')]\n",
        "TARGET_COL = 'RUL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected features: ['op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_measurement_1', 'sensor_measurement_2', 'sensor_measurement_3', 'sensor_measurement_4', 'sensor_measurement_5', 'sensor_measurement_6', 'sensor_measurement_7', 'sensor_measurement_8', 'sensor_measurement_9', 'sensor_measurement_10', 'sensor_measurement_11', 'sensor_measurement_12', 'sensor_measurement_13', 'sensor_measurement_14', 'sensor_measurement_15', 'sensor_measurement_16', 'sensor_measurement_17', 'sensor_measurement_18', 'sensor_measurement_19', 'sensor_measurement_20', 'sensor_measurement_21']\n"
          ]
        }
      ],
      "source": [
        "variances = df[FEATURE_COLS].var()\n",
        "selected_features = variances[variances > 0.01].index.tolist()  # Keep features with variance > 0.01\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "df = df[['unit_number'] + selected_features + [TARGET_COL]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_features = StandardScaler()\n",
        "scaler_target = StandardScaler()\n",
        "\n",
        "df[selected_features] = scaler_features.fit_transform(df[selected_features])\n",
        "\n",
        "df[TARGET_COL] = scaler_target.fit_transform(df[[TARGET_COL]])\n",
        "\n",
        "if df.isna().any().any():\n",
        "    print(\"NaN values found after normalization. Removing rows with NaN.\")\n",
        "    df = df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequences(data, window_size, feature_cols, target_col):\n",
        "    X, y = [], []\n",
        "    for unit in data['unit_number'].unique():\n",
        "        unit_data = data[data['unit_number'] == unit]\n",
        "        feature_data = unit_data[feature_cols].values\n",
        "        target_data = unit_data[target_col].values\n",
        "        for i in range(len(unit_data) - window_size):\n",
        "            X.append(feature_data[i:i+window_size])\n",
        "            y.append(target_data[i+window_size])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = create_sequences(df, WINDOW_SIZE, selected_features, TARGET_COL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "if np.any(np.isnan(X)) or np.any(np.isnan(y)):\n",
        "    print(\"NaN values found in sequences. Removing affected samples.\")\n",
        "    mask = ~np.isnan(X).any(axis=(1, 2)) & ~np.isnan(y)\n",
        "    X, y = X[mask], y[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "input_shape = X.shape[1:] \n",
        "inputs = Input(shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv1D(filters=256, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Dropout(0.2)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,672</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m4,672\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,481</span> (923.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m236,481\u001b[0m (923.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,585</span> (920.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,585\u001b[0m (920.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)  # Reduced learning rate and added gradient clipping\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - loss: 0.8281 - mae: 0.7074 - val_loss: 0.3320 - val_mae: 0.4897 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - loss: 0.3412 - mae: 0.4580 - val_loss: 0.2897 - val_mae: 0.4482 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - loss: 0.3153 - mae: 0.4402 - val_loss: 0.2672 - val_mae: 0.4316 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 22ms/step - loss: 0.3020 - mae: 0.4284 - val_loss: 0.2599 - val_mae: 0.4199 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - loss: 0.2885 - mae: 0.4193 - val_loss: 0.2487 - val_mae: 0.4198 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.2672 - mae: 0.4001 - val_loss: 0.2387 - val_mae: 0.4100 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - loss: 0.2539 - mae: 0.3911 - val_loss: 0.2153 - val_mae: 0.3869 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.2456 - mae: 0.3829 - val_loss: 0.2005 - val_mae: 0.3649 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.2314 - mae: 0.3696 - val_loss: 0.1848 - val_mae: 0.3482 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.2161 - mae: 0.3578 - val_loss: 0.1766 - val_mae: 0.3461 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - loss: 0.2132 - mae: 0.3533 - val_loss: 0.1620 - val_mae: 0.3247 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 23ms/step - loss: 0.2031 - mae: 0.3431 - val_loss: 0.1908 - val_mae: 0.3497 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1940 - mae: 0.3360 - val_loss: 0.1566 - val_mae: 0.3287 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1836 - mae: 0.3255 - val_loss: 0.1355 - val_mae: 0.2897 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1808 - mae: 0.3230 - val_loss: 0.1245 - val_mae: 0.2683 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1698 - mae: 0.3098 - val_loss: 0.1547 - val_mae: 0.3142 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1647 - mae: 0.3059 - val_loss: 0.1206 - val_mae: 0.2716 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - loss: 0.1601 - mae: 0.3005 - val_loss: 0.1148 - val_mae: 0.2611 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1553 - mae: 0.2954 - val_loss: 0.1061 - val_mae: 0.2477 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 21ms/step - loss: 0.1515 - mae: 0.2916 - val_loss: 0.1141 - val_mae: 0.2683 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1502 - mae: 0.2895 - val_loss: 0.0967 - val_mae: 0.2438 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 21ms/step - loss: 0.1440 - mae: 0.2836 - val_loss: 0.0943 - val_mae: 0.2384 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1377 - mae: 0.2776 - val_loss: 0.1162 - val_mae: 0.2713 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - loss: 0.1350 - mae: 0.2737 - val_loss: 0.1003 - val_mae: 0.2442 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 21ms/step - loss: 0.1315 - mae: 0.2697 - val_loss: 0.0967 - val_mae: 0.2447 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - loss: 0.1296 - mae: 0.2669 - val_loss: 0.0941 - val_mae: 0.2463 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - loss: 0.1246 - mae: 0.2619 - val_loss: 0.0834 - val_mae: 0.2165 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1236 - mae: 0.2609 - val_loss: 0.0848 - val_mae: 0.2202 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - loss: 0.1194 - mae: 0.2553 - val_loss: 0.0848 - val_mae: 0.2157 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1211 - mae: 0.2563 - val_loss: 0.0842 - val_mae: 0.2225 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 22ms/step - loss: 0.1138 - mae: 0.2502 - val_loss: 0.1104 - val_mae: 0.2597 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - loss: 0.1132 - mae: 0.2479 - val_loss: 0.0723 - val_mae: 0.2044 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1144 - mae: 0.2488 - val_loss: 0.0711 - val_mae: 0.2003 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 21ms/step - loss: 0.1109 - mae: 0.2466 - val_loss: 0.0875 - val_mae: 0.2280 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 21ms/step - loss: 0.1107 - mae: 0.2462 - val_loss: 0.0667 - val_mae: 0.1939 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 22ms/step - loss: 0.1087 - mae: 0.2429 - val_loss: 0.0770 - val_mae: 0.2244 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1077 - mae: 0.2413 - val_loss: 0.0671 - val_mae: 0.2110 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.1030 - mae: 0.2368 - val_loss: 0.0596 - val_mae: 0.1968 - learning_rate: 5.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1022 - mae: 0.2354 - val_loss: 0.0866 - val_mae: 0.2177 - learning_rate: 5.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - loss: 0.1012 - mae: 0.2337 - val_loss: 0.0599 - val_mae: 0.1791 - learning_rate: 5.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0975 - mae: 0.2294 - val_loss: 0.0680 - val_mae: 0.2007 - learning_rate: 5.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 22ms/step - loss: 0.0969 - mae: 0.2283 - val_loss: 0.0701 - val_mae: 0.1995 - learning_rate: 5.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0976 - mae: 0.2288 - val_loss: 0.0559 - val_mae: 0.1754 - learning_rate: 5.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 22ms/step - loss: 0.0950 - mae: 0.2266 - val_loss: 0.0613 - val_mae: 0.1822 - learning_rate: 5.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - loss: 0.0925 - mae: 0.2245 - val_loss: 0.0647 - val_mae: 0.1976 - learning_rate: 5.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.0923 - mae: 0.2235 - val_loss: 0.0685 - val_mae: 0.1923 - learning_rate: 5.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 0.0947 - mae: 0.2243 - val_loss: 0.0537 - val_mae: 0.1736 - learning_rate: 5.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0922 - mae: 0.2224 - val_loss: 0.0557 - val_mae: 0.1841 - learning_rate: 5.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0889 - mae: 0.2182 - val_loss: 0.0641 - val_mae: 0.1855 - learning_rate: 5.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0897 - mae: 0.2195 - val_loss: 0.0538 - val_mae: 0.1610 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, lr_scheduler],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "if np.any(np.isnan(y_pred)):\n",
        "    print(\"NaN values found in predictions. Replacing with 0.\")\n",
        "    y_pred = np.nan_to_num(y_pred, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_val_inv = scaler_target.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
        "y_pred_inv = scaler_target.inverse_transform(y_pred).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "if np.any(np.isnan(y_val_inv)) or np.any(np.isnan(y_pred_inv)):\n",
        "    print(\"NaN values found after inverse transformation. Removing affected samples.\")\n",
        "    mask = ~np.isnan(y_val_inv) & ~np.isnan(y_pred_inv)\n",
        "    y_val_inv, y_pred_inv = y_val_inv[mask], y_pred_inv[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
        "mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_val_inv, y_pred_inv)\n",
        "mape = mean_absolute_percentage_error(y_val_inv, y_pred_inv)\n",
        "medae = median_absolute_error(y_val_inv, y_pred_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 97.3889\n",
            "MAE: 7.3907\n",
            "RMSE: 9.8686\n",
            "R² Score: 0.9478\n",
            "MAPE: 4668151777395.25%\n",
            "Median Absolute Error: 5.0792\n"
          ]
        }
      ],
      "source": [
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"Median Absolute Error: {medae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss During Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('training_loss_plot.png')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_val_inv, y_pred_inv, alpha=0.5, color='blue')\n",
        "plt.plot([y_val_inv.min(), y_val_inv.max()], [y_val_inv.min(), y_val_inv.max()], 'r--', lw=2, label='Ideal Fit')\n",
        "plt.title('Predicted vs Actual RUL')\n",
        "plt.xlabel('Actual RUL')\n",
        "plt.ylabel('Predicted RUL')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('predicted_vs_actual_rul.png')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importance = pd.Series(variances.loc[selected_features], index=selected_features)\n",
        "plt.figure(figsize=(12, 6))\n",
        "feature_importance.sort_values(ascending=False).plot(kind='bar')\n",
        "plt.title('Feature Importance Based on Variance')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Variance')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance_plot.png')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"fixed_enhanced_cnn_rul_model.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
